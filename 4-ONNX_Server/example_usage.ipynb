{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Model Server Example Usage\n",
    "\n",
    "This notebook demonstrates how to interact with the ONNX model serving API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# API base URL\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "print(\"ONNX Model Server API Demo\")\n",
    "print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the service is healthy\n",
    "response = requests.get(f\"{BASE_URL}/\")\n",
    "health_info = response.json()\n",
    "\n",
    "print(\"Health Check:\")\n",
    "print(json.dumps(health_info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed model information\n",
    "response = requests.get(f\"{BASE_URL}/model/info\")\n",
    "model_info = response.json()\n",
    "\n",
    "print(\"Model Information:\")\n",
    "print(json.dumps(model_info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample input data\n",
    "response = requests.get(f\"{BASE_URL}/sample\")\n",
    "sample_data = response.json()\n",
    "\n",
    "print(\"Sample Data:\")\n",
    "print(json.dumps(sample_data, indent=2))\n",
    "\n",
    "# Extract test input for predictions\n",
    "test_input = sample_data.get(\"test_input\", [])\n",
    "expected_output = sample_data.get(\"expected_output\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using sample data\n",
    "if test_input:\n",
    "    prediction_request = {\n",
    "        \"data\": test_input\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/predict\",\n",
    "        json=prediction_request,\n",
    "        headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        predictions = response.json()\n",
    "        \n",
    "        print(\"Predictions:\")\n",
    "        print(json.dumps(predictions, indent=2))\n",
    "        \n",
    "        # Compare with expected output\n",
    "        if expected_output:\n",
    "            print(\"\\nComparison with Expected Output:\")\n",
    "            for i, (pred, expected) in enumerate(zip(predictions[\"predictions\"], expected_output)):\n",
    "                status = \"✅\" if pred == expected else \"❌\"\n",
    "                print(f\"Sample {i+1}: Predicted={pred}, Expected={expected} {status}\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "else:\n",
    "    print(\"No test input available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom input data\n",
    "custom_input = np.random.randn(3, 10).tolist()  # 3 samples with 10 features each\n",
    "\n",
    "custom_request = {\n",
    "    \"data\": custom_input\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/predict\",\n",
    "    json=custom_request,\n",
    "    headers={\"Content-Type\": \"application/json\"}\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    custom_predictions = response.json()\n",
    "    \n",
    "    print(\"Custom Predictions:\")\n",
    "    print(f\"Input shape: {np.array(custom_input).shape}\")\n",
    "    print(f\"Predictions: {custom_predictions['predictions']}\")\n",
    "    \n",
    "    if custom_predictions['probabilities']:\n",
    "        print(\"\\nClass Probabilities:\")\n",
    "        for i, probs in enumerate(custom_predictions['probabilities']):\n",
    "            print(f\"Sample {i+1}: {[f'{p:.3f}' for p in probs]}\")\nelse:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Performance test with multiple requests\n",
    "n_requests = 10\n",
    "batch_size = 5\n",
    "\n",
    "print(f\"Performance Test: {n_requests} requests with {batch_size} samples each\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "times = []\n",
    "for i in range(n_requests):\n",
    "    # Generate random input\n",
    "    random_input = np.random.randn(batch_size, 10).tolist()\n",
    "    \n",
    "    request_data = {\"data\": random_input}\n",
    "    \n",
    "    # Measure request time\n",
    "    start_time = time.time()\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/predict\",\n",
    "        json=request_data,\n",
    "        headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    request_time = (end_time - start_time) * 1000  # Convert to ms\n",
    "    times.append(request_time)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Request {i+1}: {request_time:.2f}ms ✅\")\n",
    "    else:\n",
    "        print(f\"Request {i+1}: {request_time:.2f}ms ❌ ({response.status_code})\")\n",
    "\n",
    "# Calculate statistics\n",
    "avg_time = np.mean(times)\n",
    "min_time = np.min(times)\n",
    "max_time = np.max(times)\n",
    "std_time = np.std(times)\n",
    "\n",
    "print(\"\\nPerformance Summary:\")\n",
    "print(f\"Average response time: {avg_time:.2f}ms\")\n",
    "print(f\"Min response time: {min_time:.2f}ms\")\n",
    "print(f\"Max response time: {max_time:.2f}ms\")\n",
    "print(f\"Standard deviation: {std_time:.2f}ms\")\n",
    "print(f\"Requests per second: ~{1000/avg_time:.1f} RPS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}